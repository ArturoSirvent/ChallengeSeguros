---
title: "EDA"
author: "Francisco Olayo Gonzalez"
date: "13/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Paquetes requeridos

```{r}
library(readxl)
library(ggplot2)
library(stats)
library(dplyr)
library(vcd)
library(glmnet)
library(insurancerating)
library(stats)
library(caret)
library(pscl)
```

# Carga de datos

Preparamos los datos, filtramos aquellos sin sentido o que juzgamos sospechosos y pasamos algunas variables a factor

```{r}

data <- read_excel("./data/base_challenge.xlsx") %>% 
  filter( Veh_val > 0, Edad < 100) %>% 
  dplyr::select(-C_postal, -C_rcmat_culpa, -C_rcmat_inoc)
  
  
data$fpag <- factor(data$fpag, labels = c('Anual efectivo', 'Anual domiciliado',"semestral esfectivo", "semestral 1ºp efectivo", "semestral domiciliado"))
#data$C_postal <- factor(data$C_postal)
data$Veh_marca <- factor(data$Veh_marca)
data$Veh_cuso <- factor(data$Veh_cuso)#codificado en dos valores , 3 y 4. Pero no sabemos las etiquetas
data$Veh_comb <- factor(data$Veh_comb)
data$Cus_des <- factor(data$Cus_des)
data$b7_puertas <- factor(data$b7_puertas, ordered = TRUE)
```

```{r}
str(data)#controlamos los datos
summary(data)
```
Lo de antes pero en automático por si acaso
```{r, waring = F}
for(i in colnames(data)){# Convertimos los vectores de texto en factores (Codigo postal, marca del vehiculo,combinacion, tipo de vehiculo, clase de vehiculo,)
  if(class(data[[i]])=="character"){
    print(i)
    data[i]= factor(data[[i]])
  }
}
```

# EDA

Empezamos revisando la distribución de algunas variables

```{r}
ggplot(data,aes(x = Score2))+geom_histogram()

rep <- filter(data, Veh_val < 100000)

hist(rep$Veh_val, breaks = 100) #Tenemos un valor solitario por debajo de 0, eliminar
hist(rep$Veh_peso, breaks = 100)
hist(data$veh_ant, breaks = 100)
#hist(data$b7_puertas, breaks = 100)
hist(data$b7_longitud, breaks = 100)
hist(data$ant_compnia, breaks = 100)
hist(data$C_rcmat_culpa, breaks = 100)
hist(data$C_rcmat_inoc, breaks = 100)
hist(data$veh_ant, breaks = 100)
```


Distribución de variables numéricas según el númeto de accindentes.
```{r}
data$N_rcmat <- factor(data$N_rcmat, ordered = TRUE)

for(i in colnames(data)){
  if(class(data[[i]]) == "numeric"){
    a <- ggplot(data = data, aes_string(x = "N_rcmat", y = i, fill = "N_rcmat"))+geom_violin()
    print(a)
  }
  
}
```

Mosaico de variables categóricas según número de accidentes
```{r}

for(i in colnames(data)){
  if(class(data[[i]]) == "character"){
    mosaicplot( as.formula(paste0(" ~ ", i,"+N_rcmat")) ,data = data)
  }
  
}
```

Tablas de contingencia de variables categóricas según número de accidentes
```{r}
for(i in colnames(data)){
  if(class(data[[i]]) == "character"){
    a <- xtabs(as.formula(paste0(" ~ ", i,"+N_rcmat")) ,data = data)
    print(a)
  }
  
}
```

```{r}
# Función que discretiza en cuantiles
quantbreaks <- function(predictor,cortes=10,cuantiles=F){
  qnt <- quantile(predictor,probs=seq(0,1,1/cortes),include.lowest=T)
  qnt[1] <- qnt[1]-0.01
  qnt[cortes] <- qnt[cortes]+0.01 
  
  if(cuantiles){return(qnt)}                # devuelve cortes 
    else{return(cut(predictor,breaks=qnt))} # devuelve var discretizada
}
```


```{r}
data2 <- data 
data2 <- data2 %>% mutate(Edad_Cat = quantbreaks(data$Edad, cortes=10), Expo_Cat =quantbreaks(data$Expo, cortes=10), 
                 Carne_Cat=quantbreaks(data$Carne, cortes=10), Veh_cdin_Cat = quantbreaks(data$Veh_cdin, cortes=5), 
                 Veh_val_Cat=quantbreaks(data$Veh_val, cortes=10))

```

```{r}
data2 %>% ggplot(aes(x=Edad_Cat, y=N_rcmat)) + stat_summary(fun = "mean", geom = "point")
```

```{r}
data2 %>% group_by(Edad_Cat) %>% summarise(media=mean(N_rcmat)) %>% 
    ggplot()+geom_point(aes(x=Edad_Cat,y=media))
```

```{r}
data2 %>% group_by(Expo_Cat) %>% summarise(media=mean(N_rcmat)) %>% 
    ggplot()+geom_point(aes(x=Expo_Cat,y=media))
```





```{r}
data2 %>% group_by(Veh_cdin_Cat) %>% summarise(media=mean(N_rcmat)) %>% 
    ggplot()+geom_point(aes(x=Veh_cdin_Cat,y=media))
```

```{r}
aux <- which(data2$Expo == 0)
data2$Expo[aux] <- 0.0001
```



## Posibles agrupaciones para categorizar

```{r}
# quitamos la marca

data3 <- data2 %>% dplyr::select(-Veh_marca) %>%
  dplyr::mutate(N_totales = N_rcmat + N_rccorp)
```


```{r}
data3 %>% group_by(Veh_cuso) %>% summarise(n())
```

```{r}
data3 %>% group_by(Carne) %>% summarise(n())
```
```{r}
data3 %>% group_by(ant_compnia) %>% summarise(n())
```

```{r}
data3 %>% ggplot() + geom_histogram(aes(x=Veh_cdin))
```



## Elección del modelo


Obsevamos que no existe exceso de ceros en la variable `N_rcmat`.
```{r}
obs <- data3 %>% group_by(N_rcmat=N_rcmat) %>% 
  summarise(observados=round(n()/24995,3))
esperados <- round(dpois(0:4,mean(data3$N_rcmat)),3)
cbind(obs,esperados)
```

Comprobamos que claramente es una poisson.
```{r}
siniestros <- data3%>% group_by(N_rcmat)%>% summarise(observados=n()/dim(data3)[1])
siniestros <- siniestros%>% mutate(esperados=dpois(N_rcmat,lambda = mean(data3$N_rcmat)))

siniestros %>% ggplot()+geom_col(aes(x=N_rcmat,y=observados),color="blue",fill="blue",alpha=0.1)+
  geom_col(aes(x=N_rcmat,y=esperados),color="red",fill="red",alpha=0.1)
```


Tampoco existe exceso de ceros en la varible `N_rccorp`.  
```{r}
obs <- data3 %>% group_by(N_rccorp=N_rccorp) %>% 
  summarise(observados=round(n()/24995,3))
esperados <- round(dpois(0:2,mean(data3$N_rccorp)),3)
cbind(obs,esperados)
```
Comprobamos que claramente es una poisson.
```{r}
siniestros <- data3%>% group_by(N_rccorp)%>% summarise(observados=n()/dim(data3)[1])
siniestros <- siniestros%>% mutate(esperados=dpois(N_rccorp,lambda = mean(data3$N_rccorp)))

siniestros %>% ggplot()+geom_col(aes(x=N_rccorp,y=observados),color="blue",fill="blue",alpha=0.1)+
  geom_col(aes(x=N_rccorp,y=esperados),color="red",fill="red",alpha=0.1)
```


Comprobamos si existe exceso de ceros en la variable suma `N_rcmat + N_rccorp`. 

```{r}
obs <- data3 %>% group_by(N_totales=N_totales) %>% 
  summarise(observados=round(n()/24995,3))
esperados <- round(dpois(0:5,mean(data3$N_totales)),3)
cbind(obs,esperados)
```

Vemos que puede existir algo de exceso de ceros en la variables suma `N_totales`. Por tanto, podría hacer falta usar un modelo para corregir dicho exceso. 

Comenzamos planteando un modelo de Poisson o una Normal de media y varianza iguales. También sería conveniente probar alguno con inflación de ceros como la binomial negativa.

Otra opción podría ser usar otro tipo de modelos como modelos de mezcla (hurdle: modeliza los ceros con una bernouilli y el resto de valores con una poisson truncada. Útil cuando hay muchos o pocos ceros), árboles de decisión, bagging,... pero lo plantearemos en el futuro. Empezaremos probando poisson y gaussiana.


Comparamos con la distribución de poisson.
```{r}
siniestros <- data3%>% group_by(N_totales)%>% summarise(observados=n()/dim(data3)[1])
siniestros <- siniestros%>% mutate(esperados=dpois(N_totales,lambda = mean(data3$N_totales)))

siniestros %>% ggplot()+geom_col(aes(x=N_totales,y=observados),color="blue",fill="blue",alpha=0.1)+
  geom_col(aes(x=N_totales,y=esperados),color="red",fill="red",alpha=0.1)
```


Comparamos con la distribución de binomial negativa.
```{r}
fit.bn <- goodfit(data3$N_totales,type = "nbinomial", method="MinChisq")

# goodfit essentially computes the fitted values of a discrete distribution (either Poisson, 
# binomial or negative binomial) to the count data given in x. If the parameters are not specified # they are estimated either by ML or Minimum Chi-squared.

negbinData <- data.frame(N_totales=0:5,
                         observados=fit.bn$observed/dim(data3)[1], 
                         esperados=fit.bn$fitted/dim(data3)[1])

negbinData%>% ggplot +
  geom_col(aes(x=N_totales,y=observados),color="blue",fill="blue",alpha=0.1) +
  geom_col(aes(x=N_totales,y=esperados),color="red",fill="red",alpha=0.1)
```
Vemos que cuando usamos la suma de reclamaciones, la distribución se ajusta perfectamente a una binomial negativa. Por tanto, si decidimos usar la variable suma, deberíamos modelizar con la binomial negativa o con algún modelo de mezcla/inflación de ceros.


Para cada uno de los posibles modelos que podemos elegir, habrá que decidir si le metemos la variable de offset o no. Otro de los aspectos que tenemos que decidir, es si usar regularización o no. Esto puede ser útil para evitar el sobreajuste si nos encontramos en dicho caso (modelos LASSO, RIDGE, ELASTICNET).

Al final nos quedaremos con el que mejor resultados nos dé.



```{r}
library(rsample)
data3 <- data3 %>% dplyr::select(-poliza,-Edad,-Carne,-fini,-fvto,-Veh_cdin,-Veh_val,-Veh_peso,-Veh_cuso,-N_rcmat,-N_rccorp,-N_culpa,-N_inoc,-C_rcmat_agregado,-C_rccorp,-fpag,-Edad_Cat,-veh_ant,-Cus_des,-b7_puertas,-Veh_val_Cat,-clase_veh,-Tipo_veh)

set.seed(1500)

particion <- initial_split(data3,prop = 2/3, strata = N_totales) # particion aleatoria pura 
train_data <- training(particion)
test_data <- testing(particion)
```





```{r}
# FALLA PORQUE PASA ALGO CON LAS VARIABLES CATEGÓRICAS

#Variable Cus_des da error

formula <- N_totales~ . -poliza-Edad-Carne-Expo-fini-fvto-Veh_cdin-Veh_val-Veh_peso-Veh_cuso-N_rcmat-N_rccorp-N_culpa-N_inoc-C_rcmat_agregado-C_rccorp-fpag-Edad_Cat-veh_ant-Cus_des-Expo_Cat-b7_puertas-Veh_val_Cat-clase_veh-Tipo_veh

#formula <- N_rcmat~ . -poliza-Edad-Carne-Expo-Veh_cdin-Veh_val-Veh_peso-N_rcmat-N_rccorp-fini-fvto-N_culpa-N_inoc-C_rcmat_agregado-C_rccorp-fpag-Tipo_veh-Cus_des-Veh_val_Cat-Edad_Cat-b7_puertas

# of_var <- log(train_data$Expo/365)

#formula <- N_rccorp~ +Score2+Veh_cuso+ant_compnia+Carne_Cat+Veh_cdin_Cat+Expo_Cat


#Po.log <- glm(N_totales~ .-Expo-N_totales, data=train_data, family=gaussian(link='log'))
No.id <- glm(N_totales~. -Expo-N_totales, data=train_data)
No.log <- glm(N_totales~. -Expo-N_totales, data=train_data, start=coef(No.id), family=gaussian(link='log'))
summary(No.log)

starting.values <- coef(Po.log)
starting.values[starting.values < 0] <- 0.0001
#mod <- lm(N_rcmat~ . -poliza-Edad-Carne-Expo-Veh_cdin-Veh_val-Veh_peso-N_rcmat-N_rccorp-fini-fvto-N_culpa-N_inoc-C_rcmat_agregado-C_rccorp-fpag,data=data2)
summary(Po.log)
 # evitamos valor esperado negativo
#Po.id <- glm(N_rcmat~ . -poliza-Edad-Carne-Expo-Veh_cdin-Veh_val-Veh_peso-N_rcmat-N_rccorp-fini-fvto-N_culpa-N_inoc-C_rcmat_agregado-C_rccorp-fpag ,data=train_data,start=starting.values,family=poisson(link="identity")) 
```


```{r}
# TEST 
# offset = log(test_data$Expo/365.25)
# 
# test_data2 <- test_data
# 
# nd <- data.frame(test_data2, offset = offset) 

#p.Po.log <- predict.glm(object = Po.log, newdata = test_data , type="response" )
p.No.log <- predict.glm(object = No.log, newdata = test_data , type="response" )

ec <- function(prediccion, observado){
  sum((prediccion-observado)^2)
}

ea <- function(prediccion, observado){
  sum(abs(prediccion-observado))
}

#ec(p.Po.log, test_data$N_totales)
#ea(p.Po.log, test_data$N_totales)
ec(p.No.log, test_data$N_totales)
ea(p.No.log, test_data$N_totales)

hist(p.Po.log)
#hist(test_data$N_totales)
#offset=log(train_data$Expo/365.25)


```
Al hacer la prediccion sobre N_rccorp, los resultados siguen una ditribucion mas parecida a una poisson, pero con N_rcmat no, no se porque todavia.

```{r}
#Codificamos las respuestas por umbrales
ind5 <- which(p.No.log > 1.4)
p.No.log[ind5] <- 5

ind4 <- which(p.No.log > 1.3 & p.No.log< 1.4)
p.No.log[ind4] <- 4

ind3 <- which(p.No.log > 1 & p.No.log< 1.3)
p.No.log[ind3] <- 3

ind2 <- which(p.No.log > 0.35 & p.No.log< 1)
p.No.log[ind2] <- 2

ind1 <- which(p.No.log > 0.185 & p.No.log< 0.35)
p.No.log[ind1] <- 1

ind0 <- which(p.No.log < 0.185)
p.No.log[ind0] <- 0
```

```{r}
length(which(p.No.log == 0))
```
```{r}
length(which(train_data$N_totales == 4))
table(train_data$N_totales)
table(test_data$N_totales)
```


```{r}
ec <- function(prediccion, observado){
  sum((prediccion-observado)^2)
}

ea <- function(prediccion, observado){
  sum(abs(prediccion-observado))
}

#ec(p.Po.log, test_data$N_totales)
#ea(p.Po.log, test_data$N_totales)

ec(p.No.log, test_data$N_totales)
ea(p.No.log, test_data$N_totales)
hist(p.Po.log)
#hist(test_data$N_rccorp)
#offset=log(train_data$Expo/365.25)


```

```{r}
#p.Po.log <- factor(p.Po.log)
p.No.log <- factor(p.No.log)
test_data$N_totales <- factor(test_data$N_totales)

confusionMatrix(p.No.log,  test_data$N_totales)

```



## Binomial negativa 

Probamos a modelar el número total de reclamaciones con una binomial negativa, ya que hemos visto que sigue prácticamente dicha distribución.


```{r}
data2 <- data 
data2 <- data2 %>% mutate(Edad_Cat = quantbreaks(data$Edad, cortes=10), Expo_Cat =quantbreaks(data$Expo, cortes=10), 
                 Carne_Cat=quantbreaks(data$Carne, cortes=4), Veh_cdin_Cat = quantbreaks(data$Veh_cdin, cortes=5), 
                 Veh_val_Cat=quantbreaks(data$Veh_val, cortes=10))

```


```{r}
library(rsample)
data3 <- data2 
#data4 <- data3 %>% dplyr::select(-poliza,-Edad,-Carne,-fini,-fvto,-Veh_cdin,-Veh_val,-Veh_peso,-Veh_cuso,-N_rcmat,-N_rccorp,-N_culpa,-N_inoc,-C_rcmat_agregado,-C_rccorp,-fpag,-Edad_Cat,-veh_ant,-Cus_des,-b7_puertas,-Veh_val_Cat,-clase_veh,-Tipo_veh-Expo)
data4 <- data3 %>% dplyr::mutate(N_totales = N_rcmat + N_rccorp) %>%
                  dplyr::select(-poliza,-Edad,-Carne,-fini,-fvto,-Veh_cdin,-Veh_val,-Veh_peso,-Veh_cuso,-N_rcmat,-N_rccorp,-N_culpa,-N_inoc,-C_rcmat_agregado,-C_rccorp,-Edad_Cat,-veh_ant,-Cus_des,-clase_veh,-Tipo_veh,-Expo)

set.seed(1500)

particion <- initial_split(data4,prop = 2/3, strata = N_totales) # particion aleatoria pura 
train_data <- training(particion)
test_data <- testing(particion)
```


```{r}
# CREAMOS EL MODELO CON TODO Y HACEMOS UN STEP

library(MASS)
NB.log <- glm.nb(N_totales~ . ,data=train_data,link="log",control=glm.control(maxit=150))
summary(NB.log)

# Eliminamos la marca del vehículo por ser muy poco significativa 

NB.log <- update(NB.log, ~. -Veh_marca)
summary(NB.log)
```

```{r}
# BUSCAMOS UN STEP PARA BUSCAR EL MEJOR MODELO 

selec <- step(NB.log, direction='both', trace=1)

```

```{r}
# Vemos un resumen del mejor modelo 
summary(selec)
```





No hay problemas de colinealidad
```{r}
library(regclass)
VIF(selec)
```

Hacemos predicciones sobre el conjunto de validación. 
```{r}
p.NB.log <- predict.glm(object = selec, newdata = test_data , type="response" )
hist(p.NB.log)

ec <- function(prediccion, observado){
  sum((prediccion-observado)^2)
}

ea <- function(prediccion, observado){
  sum(abs(prediccion-observado))
}

ecm <- function(prediccion, observado){
  sum((prediccion-observado)^2)/dim(test_data)[1]
}

ec(p.NB.log, test_data$N_totales)
ea(p.NB.log, test_data$N_totales)
ecm(p.NB.log, test_data$N_totales)

```

## PREDICCIONES


```{r}
library(readxl)
data_test <- read_excel("data/base_challenge.xlsx", sheet = "Test")
#View(data_test)
```

```{r}
# Creamos las variables categóricas para el conjunto de test también. Solo lo hacemos para aquellas que están incluidas en el modelo.

# Primero replicamos los niveles de las variables categóricas usadas en el modelo durante el entrenamiento. 

qntExpo <- quantbreaks(data$Expo, cortes=10,cuantiles=T)
qntCarne <- quantbreaks(data$Carne, cortes=4, cuantiles=T)
qntVeh_cdin <- quantbreaks(data$Veh_cdin, cortes=5, cuantiles=T)

data_test <- data_test %>% mutate(Expo_Cat =cut(Expo, qntExpo), Carne_Cat=cut(Carne, qntCarne), Veh_cdin_Cat = cut(Veh_cdin, qntVeh_cdin))
```


```{r}
p.NB.log.test <- predict.glm(object = selec, newdata = data_test , type="response" )
hist(p.NB.log.test)

ec <- function(prediccion, observado){
  sum((prediccion-observado)^2)
}

ea <- function(prediccion, observado){
  sum(abs(prediccion-observado))
}

ecm <- function(prediccion, observado){
  sum((prediccion-observado)^2)/dim(test_data)[1]
}

#ec(p.NB.log.test, test_data$N_totales)
#ea(p.NB.log.test, test_data$N_totales)
#ecm(p.NB.log.test, test_data$N_totales)
```


```{r}
data_test <- data_test %>% mutate(Preds = p.NB.log.test)
```

```{r}
save(data_test, file='./Predicciones.RData')
```









